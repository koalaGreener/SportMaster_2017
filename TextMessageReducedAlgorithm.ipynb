{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import sort\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The config for the database\n",
    "config = {\n",
    "  'user': 'jake',\n",
    "  'password': 'jake',\n",
    "  'host': '127.0.0.1',\n",
    "  'database': 'SportMaster',\n",
    "  'raise_on_warnings': True,\n",
    "}\n",
    "cnx = mysql.connector.connect(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Personality\n",
    "\n",
    "age = (\"\"\"SELECT \n",
    "    sm_clients.`client_reg_code`, t2.age\n",
    "FROM\n",
    "    sm_clients\n",
    "        LEFT JOIN\n",
    "    (SELECT \n",
    "        sm_clients.`CLIENT_REG_CODE`,\n",
    "            TIMESTAMPDIFF(YEAR, sm_clients.birthday, '2016-10-13') AS age\n",
    "    FROM\n",
    "        sm_clients) t2 ON sm_clients.`CLIENT_REG_CODE` = t2.`CLIENT_REG_CODE`\n",
    "WHERE\n",
    "    sm_clients.client_reg_code IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "HAVING t2.age >= 14\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "gender = (\"\"\"SELECT \n",
    "    sm_clients.client_reg_code, sm_clients.sex\n",
    "FROM\n",
    "    sm_clients\n",
    "WHERE\n",
    "    sm_clients.client_reg_code IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "ismobile_isemail = (\"\"\"SELECT \n",
    "    sm_clients.client_reg_code,\n",
    "    sm_clients.ismobile,\n",
    "    sm_clients.isemail\n",
    "FROM\n",
    "    sm_clients\n",
    "WHERE\n",
    "    sm_clients.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "\"\"\")\n",
    "\n",
    "#Merge all the Personality Data\n",
    "age_df = pd.read_sql_query(age, cnx)\n",
    "gender_df = pd.read_sql_query(gender, cnx)\n",
    "ismobile_isemail_df = pd.read_sql_query(ismobile_isemail, cnx)\n",
    "\n",
    "Personality = age_df.merge(gender_df, how = 'left', on='client_reg_code')\\\n",
    ".merge(ismobile_isemail_df, how = 'left',on='client_reg_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Geographically related\n",
    "\n",
    "inMoscow = (\"\"\"\n",
    "SELECT \n",
    "    sm_clients.client_reg_code, 1 as inMoscow\n",
    "FROM\n",
    "    sm_clients\n",
    "WHERE\n",
    "    ADDR_CITY = 'Москва';\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "inStPetersburg = (\"\"\"\n",
    "SELECT \n",
    "    sm_clients.client_reg_code, 1 as inStPetersburg\n",
    "FROM\n",
    "    sm_clients\n",
    "WHERE\n",
    "    ADDR_CITY = 'Санкт-Петербург';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "avgVisitors = (\"\"\"\n",
    "SELECT \n",
    "    sm_clients.`client_reg_code`, t2.AVGVisitors\n",
    "FROM\n",
    "    sm_clients\n",
    "        LEFT JOIN\n",
    "    (SELECT \n",
    "        sm_shops_visitors.shop,\n",
    "            AVG(sm_shops_visitors.visitors) AS AVGVisitors\n",
    "    FROM\n",
    "        sm_shops_visitors\n",
    "    GROUP BY sm_shops_visitors.shop) t2 ON sm_clients.place_shop = t2.shop\n",
    "WHERE\n",
    "    sm_clients.client_reg_code IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "registerSQT_registerSQTtrade = (\"\"\"\n",
    "SELECT \n",
    "    sm_clients.client_reg_code,\n",
    "    t2.RegisterSQT,\n",
    "    t2.Register_SQT_trade\n",
    "FROM\n",
    "    sm_clients\n",
    "        LEFT JOIN\n",
    "    (SELECT \n",
    "        sm_shops_sprav.shop,\n",
    "            sm_shops_sprav.SQT AS RegisterSQT,\n",
    "            sm_shops_sprav.SQT_trade AS Register_SQT_trade\n",
    "    FROM\n",
    "        sm_shops_sprav) t2 ON sm_clients.place_shop = t2.shop\n",
    "WHERE\n",
    "    sm_clients.client_reg_code IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "avgVisitorsBetweenPromotion = (\"\"\"\n",
    "SELECT \n",
    "    sm_clients.client_reg_code, t2.AVGVisitorsBetweenPromotion\n",
    "FROM\n",
    "    sm_clients\n",
    "        LEFT JOIN\n",
    "    (SELECT \n",
    "        sm_shops_visitors.shop,\n",
    "            AVG(sm_shops_visitors.visitors) AS AVGVisitorsBetweenPromotion\n",
    "    FROM\n",
    "        sm_shops_visitors\n",
    "    WHERE\n",
    "        dat BETWEEN '28.08.2014' AND '31.08.2014'\n",
    "    GROUP BY sm_shops_visitors.shop) t2 ON sm_clients.place_shop = t2.shop\n",
    "WHERE\n",
    "    sm_clients.client_reg_code IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "HAVING t2.AVGVisitorsBetweenPromotion IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "#Merge all the Personality Data\n",
    "inMoscow_df = pd.read_sql_query(inMoscow, cnx)\n",
    "inStPetersburg_df = pd.read_sql_query(inStPetersburg, cnx)\n",
    "avgVisitors_df = pd.read_sql_query(avgVisitors, cnx)\n",
    "registerSQT_registerSQTtrade_df = pd.read_sql_query(registerSQT_registerSQTtrade, cnx)\n",
    "avgVisitorsBetweenPromotion_df = pd.read_sql_query(avgVisitorsBetweenPromotion, cnx)\n",
    "\n",
    "\n",
    "Geographically = Personality\\\n",
    ".merge(inMoscow_df, how = 'left', on='client_reg_code')\\\n",
    ".merge(inStPetersburg_df, how = 'left', on='client_reg_code')\\\n",
    ".merge(avgVisitors_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(registerSQT_registerSQTtrade_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(avgVisitorsBetweenPromotion_df, how = 'left',on='client_reg_code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ｃonsumption Record\n",
    "\n",
    "OrginalPrice_PayAmount_UsedBonus_DiscountAmount_AfterDec2013 = (\"\"\"\n",
    "SELECT \n",
    "    sm_checks.client_reg_code,\n",
    "    SUM(sm_checks.`SUMMA_FULL`) AS OrginalPrice_AfterDec2013,\n",
    "    SUM(sm_checks.`SUMMA_MONEY`) AS PayAmount_in_total_AfterDec2013,\n",
    "    SUM(sm_checks.`SUMMA_BONUS`) AS UsedBonus_in_total_AfterDec2013,\n",
    "    SUM(sm_checks.`SUMMA_DISCOUNT`) AS DiscountAmount_in_total_AfterDec2013\n",
    "FROM\n",
    "    sm_checks\n",
    "WHERE\n",
    "    sm_checks.client_reg_code IN (SELECT \n",
    "            sm_communication.client_reg_code\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "     And sm_checks.CHECK_DAT > '2013-12-01'    \n",
    "GROUP BY sm_checks.client_reg_code\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "Spent_money_in_total_AND_Spent_bonus_in_total = (\"\"\"\n",
    "SELECT \n",
    "    sm_checks.client_reg_code,\n",
    "    SUM(sm_checks.`SUMMA_MONEY`) AS Spent_money_in_total,\n",
    "    SUM(sm_checks.`SUMMA_bonus`) AS Spent_bonus_in_total\n",
    "FROM\n",
    "    sm_checks\n",
    "WHERE\n",
    "    sm_checks.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "GROUP BY sm_checks.client_reg_code\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "Buying_item_num = (\"\"\"\n",
    "SELECT \n",
    "    sm_checks.client_reg_code,\n",
    "    COUNT(sm_checks.`CHECK_LIST_CODE`) AS Buying_item_num\n",
    "FROM\n",
    "    sm_checks\n",
    "WHERE\n",
    "    sm_checks.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "GROUP BY sm_checks.client_reg_code\n",
    "\"\"\")\n",
    "\n",
    "Discount_amount_in_total = (\"\"\"\n",
    "SELECT \n",
    "    sm_checks.client_reg_code,\n",
    "    SUM(sm_checks.`SUMMA_discount`) AS Discount_amount_in_total\n",
    "FROM\n",
    "    sm_checks\n",
    "WHERE\n",
    "    sm_checks.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "GROUP BY sm_checks.client_reg_code\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "Orginal_Price_Over_1000 = (\"\"\"\n",
    "SELECT \n",
    "    sm_checks.client_reg_code,\n",
    "    COUNT(sm_checks.`SUMMA_full`) AS Orginal_Price_Over_1000\n",
    "FROM\n",
    "    sm_checks\n",
    "WHERE\n",
    "    sm_checks.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "        AND sm_checks.`SUMMA_full` > 1000\n",
    "GROUP BY sm_checks.client_reg_code\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "QuantityAmount = (\"\"\"\n",
    "SELECT \n",
    "    sm_checks.client_reg_code,\n",
    "    COUNT(sm_checks.`quantity`) AS QuantityAmount\n",
    "FROM\n",
    "    sm_checks\n",
    "WHERE\n",
    "    sm_checks.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "GROUP BY sm_checks.client_reg_code\n",
    "\"\"\")\n",
    "\n",
    "Maximun_Bonus = (\"\"\"\n",
    "SELECT \n",
    "    sm_bonus_nach.client_reg_code,\n",
    "    MAX(sm_bonus_nach.SUMMA) AS Maximun_Bonus\n",
    "FROM\n",
    "    sm_bonus_nach\n",
    "WHERE\n",
    "    sm_bonus_nach.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "GROUP BY sm_bonus_nach.client_reg_code\n",
    "\"\"\")\n",
    "\n",
    "TotalBonusUsed = (\"\"\"\n",
    "SELECT \n",
    "    sm_bonus_nach.client_reg_code,\n",
    "    SUM(sm_bonus_nach.`SPIS_SUMMA`) AS TotalBonusUsed\n",
    "FROM\n",
    "    sm_bonus_nach\n",
    "WHERE\n",
    "    sm_bonus_nach.CLIENT_REG_CODE IN (SELECT \n",
    "            sm_communication.`CLIENT_REG_CODE`\n",
    "        FROM\n",
    "            sm_communication\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2)\n",
    "GROUP BY sm_bonus_nach.client_reg_code\n",
    "\"\"\")\n",
    "\n",
    "#Merge all the Ｃonsumption Record\n",
    "OrginalPrice_PayAmount_UsedBonus_DiscountAmount_AfterDec2013_df = pd.read_sql_query(OrginalPrice_PayAmount_UsedBonus_DiscountAmount_AfterDec2013, cnx)\n",
    "Spent_money_in_total_AND_Spent_bonus_in_total_df = pd.read_sql_query(Spent_money_in_total_AND_Spent_bonus_in_total, cnx)\n",
    "Buying_item_num_df = pd.read_sql_query(Buying_item_num, cnx)\n",
    "Discount_amount_in_total_df = pd.read_sql_query(Discount_amount_in_total, cnx)\n",
    "Orginal_Price_Over_1000_df = pd.read_sql_query(Orginal_Price_Over_1000, cnx)\n",
    "QuantityAmount_df = pd.read_sql_query(QuantityAmount, cnx)\n",
    "Maximun_Bonus_df = pd.read_sql_query(Maximun_Bonus, cnx)\n",
    "TotalBonusUsed_df = pd.read_sql_query(TotalBonusUsed, cnx)\n",
    "\n",
    "Merged_Dataset = Geographically\\\n",
    ".merge(OrginalPrice_PayAmount_UsedBonus_DiscountAmount_AfterDec2013_df, how = 'left', on='client_reg_code')\\\n",
    ".merge(Spent_money_in_total_AND_Spent_bonus_in_total_df, how = 'left', on='client_reg_code')\\\n",
    ".merge(Buying_item_num_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(Discount_amount_in_total_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(Orginal_Price_Over_1000_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(QuantityAmount_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(Maximun_Bonus_df, how = 'left',on='client_reg_code')\\\n",
    ".merge(TotalBonusUsed_df, how = 'left',on='client_reg_code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Label = (\"\"\"\n",
    "SELECT DISTINCT\n",
    "    `sm_communication`.client_reg_code, 0 as label\n",
    "FROM\n",
    "    `sm_communication`\n",
    "WHERE\n",
    "    `sm_communication`.`CLIENT_REG_CODE` NOT IN (SELECT DISTINCT\n",
    "            (sm_communication.`CLIENT_REG_CODE`)\n",
    "        FROM\n",
    "            sm_communication\n",
    "                LEFT JOIN\n",
    "            sm_checks ON sm_communication.`CLIENT_REG_CODE` = sm_checks.`CLIENT_REG_CODE`\n",
    "        WHERE\n",
    "            sm_communication.action_code = 1693\n",
    "                AND sm_communication.`STATE` = 2\n",
    "                AND (sm_checks.check_dat BETWEEN '2014-08-28 00:00:00' AND '2014-08-31 23:59:59'))\n",
    "        AND sm_communication.action_code = 1693\n",
    "        AND sm_communication.`STATE` = 2 \n",
    "UNION ALL (SELECT DISTINCT\n",
    "    (sm_communication.client_reg_code), 1 as label\n",
    "FROM\n",
    "    sm_communication\n",
    "        LEFT JOIN\n",
    "    sm_checks ON sm_communication.`CLIENT_REG_CODE` = sm_checks.`CLIENT_REG_CODE`\n",
    "WHERE\n",
    "    sm_communication.action_code = 1693\n",
    "        AND sm_communication.`STATE` = 2\n",
    "        AND (sm_checks.check_dat BETWEEN '2014-08-28 00:00:00' AND '2014-08-31 23:59:59'))\n",
    "\"\"\")\n",
    "\n",
    "Label_df = pd.read_sql_query(Label, cnx)\n",
    "dataset = Merged_Dataset.merge(Label_df, how = 'left', on='client_reg_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dataset = dataset.fillna(dataset.mean())\n",
    "#dataset.isnull().sum()\n",
    "#43% 1 57% 0\n",
    "#dataset['sex'].value_counts()\n",
    "#dataset = dataset.drop('inStPetersburg', 1)\n",
    "#dataset.to_csv('Default_dataset_without_preprocess.csv',index=False)\n",
    "\n",
    "'''\n",
    "# Gender Categorical Variable to Dummy Variables\n",
    "dataset['sex'] = dataset['sex'].fillna(0.5)\n",
    "df_sex = pd.get_dummies(dataset['sex'])\n",
    "df_sex.columns = ['female', 'missing_sex', 'male']\n",
    "dataset = dataset.join(df_sex)\n",
    "dataset = dataset.drop('sex', 1)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Scale\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Default_dataset_without_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the dataset into X, and Y\n",
    "Y = dataset[\"label\"]\n",
    "X = dataset.drop(\"label\",1)\n",
    "# evaluate the model by splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=400, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=8, seed=0, silent=True, subsample=0.7),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_delta_step': [3]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_Grid_search = {\n",
    "    'max_delta_step'  : [3],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator = xgboost.XGBClassifier(\n",
    "        n_estimators = 400,\n",
    "        learning_rate = 0.1,\n",
    "        scale_pos_weight = 8,\n",
    "        subsample = 0.7,\n",
    "        min_child_weight = 1,\n",
    "        max_depth = 3\n",
    "        \n",
    "                                                    #max_delta_step = 2,\n",
    "                                                    #scale_pos_weight = 16,\n",
    "                                                    #gamma = 0.4,\n",
    "                                                    #colsample_bytree = 0.8,\n",
    "                                                    #subsample = 0.9,\n",
    "                                                    #reg_alpha = 100\n",
    "    ), scoring = 'neg_log_loss', param_grid = parameter_Grid_search, cv = 3)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: -0.25880, std: 0.00080, params: {'max_delta_step': 3}] {'max_delta_step': 3} -0.2587967652808196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.94      0.95    205563\n",
      "          1       0.14      0.28      0.19      7727\n",
      "\n",
      "avg / total       0.94      0.91      0.93    213290\n",
      "\n",
      "f1_score: 92.69%\n",
      "roc_auc_score: 80.48%\n",
      "accuracy_score: 91.41%\n",
      "cohen_kappa_score: 0.15\n",
      "[[192803  12760]\n",
      " [  5570   2157]]\n",
      "{'Spent_bonus_in_total': 120, 'Register_SQT_trade': 56, 'Buying_item_num': 333, 'client_reg_code': 55, 'DiscountAmount_in_total_AfterDec2013': 161, 'Spent_money_in_total': 218, 'age': 238, 'AVGVisitors': 101, 'TotalBonusUsed': 154, 'Orginal_Price_Over_1000': 109, 'Discount_amount_in_total': 124, 'PayAmount_in_total_AfterDec2013': 248, 'OrginalPrice_AfterDec2013': 253, 'AVGVisitorsBetweenPromotion': 58, 'RegisterSQT': 89, 'UsedBonus_in_total_AfterDec2013': 179, 'Maximun_Bonus': 239}\n"
     ]
    }
   ],
   "source": [
    "print(clf.grid_scores_, clf.best_params_, clf.best_score_)\n",
    "\n",
    "estimator = clf.best_estimator_\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "probs = estimator.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"f1_score: %.2f%%\" % (metrics.f1_score(y_test, y_pred, pos_label = 1, average = 'weighted') * 100.0))\n",
    "\n",
    "print(\"roc_auc_score: %.2f%%\" % (metrics.roc_auc_score(y_test, probs[:, 1]) * 100.00))\n",
    "\n",
    "print(\"accuracy_score: %.2f%%\" % (metrics.accuracy_score(y_test, y_pred) * 100.00))\n",
    "\n",
    "print(\"cohen_kappa_score: %.2f\" % (metrics.cohen_kappa_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "\n",
    "#print(clf.best_estimator_.booster().get_fscore())\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plot_importance(clf.best_estimator_)\n",
    "\n",
    "#xgboost.plot_tree(clf.best_estimator_)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=25, f1_score: 92.71%\n",
      "Thresh=0.000, n=25, roc_auc_score: 80.98%\n",
      "Thresh=0.000, n=25, Accuracy: 91.51%\n",
      "Thresh=0.000, n=25, f1_score: 92.71%\n",
      "Thresh=0.000, n=25, roc_auc_score: 80.98%\n",
      "Thresh=0.000, n=25, Accuracy: 91.51%\n",
      "Thresh=0.001, n=23, f1_score: 92.71%\n",
      "Thresh=0.001, n=23, roc_auc_score: 80.94%\n",
      "Thresh=0.001, n=23, Accuracy: 91.50%\n",
      "Thresh=0.003, n=22, f1_score: 92.72%\n",
      "Thresh=0.003, n=22, roc_auc_score: 80.94%\n",
      "Thresh=0.003, n=22, Accuracy: 91.53%\n",
      "Thresh=0.003, n=21, f1_score: 92.72%\n",
      "Thresh=0.003, n=21, roc_auc_score: 80.94%\n",
      "Thresh=0.003, n=21, Accuracy: 91.52%\n",
      "Thresh=0.007, n=20, f1_score: 92.73%\n",
      "Thresh=0.007, n=20, roc_auc_score: 80.99%\n",
      "Thresh=0.007, n=20, Accuracy: 91.54%\n",
      "Thresh=0.007, n=20, f1_score: 92.73%\n",
      "Thresh=0.007, n=20, roc_auc_score: 80.99%\n",
      "Thresh=0.007, n=20, Accuracy: 91.54%\n",
      "Thresh=0.010, n=18, f1_score: 92.71%\n",
      "Thresh=0.010, n=18, roc_auc_score: 80.91%\n",
      "Thresh=0.010, n=18, Accuracy: 91.51%\n",
      "Thresh=0.017, n=17, f1_score: 92.68%\n",
      "Thresh=0.017, n=17, roc_auc_score: 80.90%\n",
      "Thresh=0.017, n=17, Accuracy: 91.47%\n",
      "Thresh=0.017, n=17, f1_score: 92.68%\n",
      "Thresh=0.017, n=17, roc_auc_score: 80.90%\n",
      "Thresh=0.017, n=17, Accuracy: 91.47%\n",
      "Thresh=0.019, n=15, f1_score: 92.72%\n",
      "Thresh=0.019, n=15, roc_auc_score: 80.82%\n",
      "Thresh=0.019, n=15, Accuracy: 91.53%\n",
      "Thresh=0.029, n=14, f1_score: 92.73%\n",
      "Thresh=0.029, n=14, roc_auc_score: 80.80%\n",
      "Thresh=0.029, n=14, Accuracy: 91.53%\n",
      "Thresh=0.032, n=13, f1_score: 92.72%\n",
      "Thresh=0.032, n=13, roc_auc_score: 80.82%\n",
      "Thresh=0.032, n=13, Accuracy: 91.54%\n",
      "Thresh=0.039, n=12, f1_score: 92.76%\n",
      "Thresh=0.039, n=12, roc_auc_score: 80.79%\n",
      "Thresh=0.039, n=12, Accuracy: 91.59%\n",
      "Thresh=0.040, n=11, f1_score: 92.72%\n",
      "Thresh=0.040, n=11, roc_auc_score: 80.81%\n",
      "Thresh=0.040, n=11, Accuracy: 91.53%\n",
      "Thresh=0.047, n=10, f1_score: 92.70%\n",
      "Thresh=0.047, n=10, roc_auc_score: 80.80%\n",
      "Thresh=0.047, n=10, Accuracy: 91.50%\n",
      "Thresh=0.048, n=9, f1_score: 92.76%\n",
      "Thresh=0.048, n=9, roc_auc_score: 80.69%\n",
      "Thresh=0.048, n=9, Accuracy: 91.62%\n",
      "Thresh=0.049, n=8, f1_score: 92.73%\n",
      "Thresh=0.049, n=8, roc_auc_score: 80.67%\n",
      "Thresh=0.049, n=8, Accuracy: 91.56%\n",
      "Thresh=0.049, n=8, f1_score: 92.73%\n",
      "Thresh=0.049, n=8, roc_auc_score: 80.67%\n",
      "Thresh=0.049, n=8, Accuracy: 91.56%\n",
      "Thresh=0.087, n=6, f1_score: 92.69%\n",
      "Thresh=0.087, n=6, roc_auc_score: 80.31%\n",
      "Thresh=0.087, n=6, Accuracy: 91.54%\n",
      "Thresh=0.092, n=5, f1_score: 92.85%\n",
      "Thresh=0.092, n=5, roc_auc_score: 79.89%\n",
      "Thresh=0.092, n=5, Accuracy: 91.85%\n",
      "Thresh=0.095, n=4, f1_score: 92.87%\n",
      "Thresh=0.095, n=4, roc_auc_score: 79.90%\n",
      "Thresh=0.095, n=4, Accuracy: 91.88%\n",
      "Thresh=0.099, n=3, f1_score: 93.02%\n",
      "Thresh=0.099, n=3, roc_auc_score: 78.88%\n",
      "Thresh=0.099, n=3, Accuracy: 92.16%\n",
      "Thresh=0.100, n=2, f1_score: 93.04%\n",
      "Thresh=0.100, n=2, roc_auc_score: 78.77%\n",
      "Thresh=0.100, n=2, Accuracy: 92.22%\n",
      "Thresh=0.109, n=1, f1_score: 93.52%\n",
      "Thresh=0.109, n=1, roc_auc_score: 76.56%\n",
      "Thresh=0.109, n=1, Accuracy: 93.43%\n"
     ]
    }
   ],
   "source": [
    "# Fit model using each importance as a threshold\n",
    "\n",
    "thresholds = sort(estimator.feature_importances_)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(estimator, threshold = thresh, prefit = True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    # train model\n",
    "    selection_model = xgboost.XGBClassifier(\n",
    "        n_estimators = 400,\n",
    "        learning_rate = 0.1,\n",
    "        scale_pos_weight = 8,\n",
    "        subsample = 0.7,\n",
    "        min_child_weight = 1,\n",
    "        max_depth = 3\n",
    "        \n",
    "                                                    #max_delta_step = 2,\n",
    "                                                    #scale_pos_weight = 16,\n",
    "                                                    #gamma = 0.4,\n",
    "                                                    #colsample_bytree = 0.8,\n",
    "                                                    #subsample = 0.9,\n",
    "                                                    #reg_alpha = 100\n",
    "    )\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    probs = selection_model.predict_proba(select_X_test)\n",
    "    \n",
    "    roc_auc_score = metrics.roc_auc_score(y_test, probs[:, 1]) * 100.00\n",
    "    f1_score = metrics.f1_score(y_test, predictions, pos_label = 1, average = 'weighted') * 100.0\n",
    "    accuracy = accuracy_score(y_test, predictions) * 100.0\n",
    "    \n",
    "    print(\"Thresh = %.3f, n = %d, f1_score: %.2f%%\" % (thresh, select_X_train.shape[1], f1_score))\n",
    "    print(\"Thresh = %.3f, n = %d, roc_auc_score: %.2f%%\" % (thresh, select_X_train.shape[1], roc_auc_score))\n",
    "    print(\"Thresh = %.3f, n = %d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
